{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy\n",
    "\n",
    "\n",
    "PATH='/home/wk/myProjects/data/Enron/oper/'\n",
    "\n",
    "TRN_PATH = 'train/'\n",
    "VAL_PATH = 'test/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "bs=32; bptt=500\n",
    "em_sz = 300  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))\n",
    "\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3\n",
    "\n",
    "learner.load_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.field.Field at 0x7fc152591860>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH=Path('/home/wk/myProjects/data/Enron/tag/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[str(i) for i in PATH.iterdir()]\n",
    "#PATH/'here.txt'.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'message-id: <17736335.1075845296221.javamail.evans@thyme> date: wed, 6 jun 2001 10:00:43 -0700 (pdt) from: david.baumbach@enron.com to: martin.thomas@enron.com, jim.schwieger@enron.com, h..wallis@enron.com subject: fw: contracts re: back-to-back deal & payment from ena to hpl on guadelupe contract mime-version: 1.0 content-type: text/plain; charset=us-ascii content-transfer-encoding: 7bit x-from: baumbach, david </o=enron/ou=na/cn=recipients/cn=dbaumba> x-to: thomas, martin </o=enron/ou=na/cn=recipients/cn=eu/cn=recipients/cn=mthomas8>, schwieger, jim </o=enron/ou=na/cn=recipients/cn=jschwie>, wallis, janet h. </o=enron/ou=na/cn=recipients/cn=jwallis> x-cc: x-bcc: x-folder: \\\\schwieger, jim\\\\schwieger, jim\\\\inbox x-origin: schwieger-j x-filename: schwieger, jim.pst fyi -----original message----- from: coffey jr., jim sent: wednesday, june 06, 2001 11:42 am to: gruesen, karen; hall, bob m; baxter, bryce; carter, carol; baumbach, david subject: contracts re: back-to-back deal & payment from ena to hpl on guadelupe contract karen/carol please prepare the wire instructions 10 business days before 7/1 and prepare the wire on 7/1. bob,bryce,david fyi. i wanted to make sure you all knew about this agreement. see the attachmnts -----original message----- from: gray, barbara sent: tuesday, june 05, 2001 3:20 pm to: coffey jr., jim subject: attached files ----- forwarded by barbara n gray/hou/ect on 06/05/2001 03:19 pm ----- \"wills, anthony\" <awills@velaw.com> 06/05/2001 10:58 am to: \"barbara gray (e-mail)\" <barbara.n.gray@enron.com> cc: subject: attached files per our conversation, attached are the referred to documents. regards, anthony anthony c. wills vinson & elkins, l.l.p. 2300 first city tower 1001 fannin houston, tx 77002-6760 713.758-4608 - phone 713.615-5507 - fax awills@velaw.com ++++++confidentiality notice+++++ the information in this email may be confidential and/or privileged. this email is intended to be reviewed by only the individual or organization named above. if you are not the intended recipient or an authorized representative of the intended recipient, you are hereby notified that any review, dissemination or copying of this email and its attachments, if any, or the information contained herein is prohibited. if you have received this email in error, please immediately notify the sender by return email and delete this email from your system. thank you <<enron: letter re back-to-back agreement.doc>> <<enron: gas contract transitional agreement.doc>> - letter re back-to-back agreement.doc - gas contract transitional agreement.doc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test\n",
    "ss=r\"\"\"\n",
    "Message-ID: <17736335.1075845296221.JavaMail.evans@thyme>\n",
    "Date: Wed, 6 Jun 2001 10:00:43 -0700 (PDT)\n",
    "From: david.baumbach@enron.com\n",
    "To: martin.thomas@enron.com, jim.schwieger@enron.com, h..wallis@enron.com\n",
    "Subject: FW: Contracts re: back-to-back deal & payment from ENA to HPL on\n",
    " Guadelupe contract\n",
    "Mime-Version: 1.0\n",
    "Content-Type: text/plain; charset=us-ascii\n",
    "Content-Transfer-Encoding: 7bit\n",
    "X-From: Baumbach, David </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DBAUMBA>\n",
    "X-To: Thomas, Martin </O=ENRON/OU=NA/CN=RECIPIENTS/CN=EU/cn=Recipients/cn=MThomas8>, Schwieger, Jim </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Jschwie>, Wallis, Janet H. </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Jwallis>\n",
    "X-cc: \n",
    "X-bcc: \n",
    "X-Folder: \\Schwieger, Jim\\Schwieger, Jim\\Inbox\n",
    "X-Origin: SCHWIEGER-J\n",
    "X-FileName: Schwieger, Jim.pst\n",
    "\n",
    "\n",
    "FYI\n",
    " -----Original Message-----\n",
    "From: \tCoffey Jr., Jim  \n",
    "Sent:\tWednesday, June 06, 2001 11:42 AM\n",
    "To:\tGruesen, Karen; Hall, Bob M; Baxter, Bryce; Carter, Carol; Baumbach, David\n",
    "Subject:\tContracts re: back-to-back deal & payment from ENA to HPL on Guadelupe contract\n",
    "\n",
    "Karen/Carol\n",
    "Please prepare the wire instructions 10 business days before 7/1 and prepare the wire on 7/1.\n",
    "\n",
    "Bob,Bryce,David\n",
    "FYI.  I wanted to make sure you all knew about this agreement.  See the attachmnts\n",
    "\n",
    " -----Original Message-----\n",
    "From: \tGray, Barbara  \n",
    "Sent:\tTuesday, June 05, 2001 3:20 PM\n",
    "To:\tCoffey Jr., Jim\n",
    "Subject:\tAttached Files\n",
    "\n",
    "\n",
    "----- Forwarded by Barbara N Gray/HOU/ECT on 06/05/2001 03:19 PM -----\n",
    "\n",
    "\n",
    "\t\"Wills, Anthony\" <awills@velaw.com> 06/05/2001 10:58 AM \t   To: \"Barbara Gray (E-mail)\" <barbara.n.gray@enron.com>  cc:   Subject: Attached Files\t\n",
    "\n",
    "\n",
    "\n",
    "Per our conversation, attached are the referred to documents.\n",
    "\n",
    "Regards,\n",
    "Anthony\n",
    "\n",
    "Anthony C. Wills\n",
    "Vinson & Elkins, L.L.P.\n",
    "2300 First City Tower\n",
    "1001 Fannin\n",
    "Houston, TX 77002-6760\n",
    "\n",
    "713.758-4608 - phone\n",
    "713.615-5507 - fax\n",
    "\n",
    "awills@velaw.com\n",
    "\n",
    "          ++++++CONFIDENTIALITY NOTICE+++++\n",
    "The information in this email may be confidential and/or privileged.  This\n",
    "email is intended to be reviewed by only the individual or organization\n",
    "named above.  If you are not the intended recipient or an authorized\n",
    "representative of the intended recipient, you are hereby notified that any\n",
    "review, dissemination or copying of this email and its attachments, if any,\n",
    "or the information contained herein is prohibited.  If you have received\n",
    "this email in error, please immediately notify the sender by return email\n",
    "and delete this email from your system.  Thank You\n",
    " <<Enron: letter re back-to-back agreement.DOC>>   <<Enron: Gas Contract\n",
    "Transitional Agreement.DOC>>\n",
    "\n",
    " -  letter re back-to-back agreement.DOC \n",
    " -  Gas Contract Transitional Agreement.DOC \n",
    "\"\"\"\n",
    "s = [TEXT.preprocess(ss)] \n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://askubuntu.com/questions/607118/cuda-not-working-after-returning-laptop-from-sleep#750939\n",
    "len(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo rmmod nvidia_uvm\n",
    "#sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.long().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos=4; @@othr_dt@@ <- 6 \n",
      "pos=5; @@othr_dt@@ <- jun \n",
      "pos=6; @@othr_dt@@ <- 2001 \n",
      "pos=29; @@othr_dt@@ <- guadelupe \n",
      "pos=163; @@othr_dt@@ <- 06/05/2001 \n",
      "pos=169; @@othr_dt@@ <- <awills@velaw.com> \n",
      "pos=178; @@othr_em@@ <- cc: \n",
      "pos=209; @@othr_ph@@ <- 713.758-4608 \n",
      "pos=210; @@othr_ph@@ <- - \n",
      "pos=212; @@othr_ph@@ <- 713.615-5507 \n",
      "pos=215; @@othr_ph@@ <- awills@velaw.com \n",
      "...\n",
      "328\n"
     ]
    }
   ],
   "source": [
    "ss = copy.deepcopy(s)\n",
    "t=TEXT.numericalize(s)\n",
    "#t = t.long().cpu()\n",
    "\n",
    "m=learner.model\n",
    "\n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "\n",
    "#m.cpu()\n",
    "#m.cuda()\n",
    "res,*_ = m(t)\n",
    "for i in range(len(s[0])):\n",
    "    n=res[-1].topk(2)[1]    \n",
    "    predict = TEXT.vocab.itos[n.data[0]]                      \n",
    "    if (predict[0:2] == '@@'):\n",
    "        print(\"pos=\" + str(i) + \"; \" + predict + \" <- \" + s[0][i] , end=' \\n')                    \n",
    "        ss[0][i]=predict\n",
    "        n.data[0] = TEXT.vocab.stoi[predict]\n",
    "    else:\n",
    "        n.data[0] = TEXT.vocab.stoi[s[0][i]]\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[n.data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1x1 (GPU 0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<unk>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TEXT.vocab.itos[e] for e in n.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
