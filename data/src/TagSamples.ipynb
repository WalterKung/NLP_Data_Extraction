{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat Enron Dataset as train and test\n",
    "##### 10% test, 90% train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "def copyf(source, destination, depth=None):\n",
    "    if not depth:\n",
    "        depth = \"\"\n",
    "    for file_or_dir in os.listdir(os.path.join(source + depth)):\n",
    "        if os.path.isfile(os.path.join(source + depth, file_or_dir)):\n",
    "#            print(\"cp \" + os.path.join(source + depth, file_or_dir) + \" \" + destination)\n",
    "            buf = depth.split(\"/\")[-2:]\n",
    "            fn = re.sub('[^0-9a-zA-Z]+', '_', \"_\".join(buf)) + '_' + file_or_dir + 'txt'\n",
    "            if randint(0,99) > 80:\n",
    "                if randint(0,99) > 85:\n",
    "                    dest = os.path.join(destination, \"test\")\n",
    "                else:\n",
    "                    dest = os.path.join(destination, \"train\")                                                    \n",
    "                if buf[1] == \"sent\":\n",
    "                    shutil.copyfile(os.path.join(source + depth, file_or_dir), os.path.join(dest, fn))\n",
    "        else:\n",
    "            copyf('', destination, os.path.join(source + depth, file_or_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"/home/wk/myProjects/data/maildir\"\n",
    "destination = \"/home/wk/myProjects/data/Enron\"\n",
    "copyf(source, destination, depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the Tag lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fn = \"/home/wk/myProjects/data/Enron/Enron_name_lookup.csv\"\n",
    "df_tag = pd.read_csv(fn, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen_p</td>\n",
       "      <td>Phillip K , Phillip</td>\n",
       "      <td>Allen</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arnold_j</td>\n",
       "      <td>John</td>\n",
       "      <td>Arnold</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arora_h</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Arora</td>\n",
       "      <td>harry.arora@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bass_e</td>\n",
       "      <td>Eric</td>\n",
       "      <td>Bass</td>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beck_s</td>\n",
       "      <td>Sally</td>\n",
       "      <td>Beck</td>\n",
       "      <td>sally.beck@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token            FirstName LastName                    Email\n",
       "0   allen_p  Phillip K , Phillip    Allen  phillip.allen@enron.com\n",
       "1  arnold_j                 John   Arnold    john.arnold@enron.com\n",
       "2   arora_h                Harry    Arora    harry.arora@enron.com\n",
       "3    bass_e                 Eric     Bass      eric.bass@enron.com\n",
       "4    beck_s                Sally     Beck     sally.beck@enron.com"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in each files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron_name_lookup.csv  \u001b[0m\u001b[01;34moper\u001b[0m/  TagSamples.ipynb  \u001b[01;34mtmp\u001b[0m/\r\n",
      "\u001b[01;34mmodels\u001b[0m/                \u001b[01;34mtag\u001b[0m/   \u001b[01;34mtest\u001b[0m/             \u001b[01;34mtrain\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='/home/wk/myProjects/data/Enron/'\n",
    "\n",
    "TRN_PATH = 'train/'\n",
    "VAL_PATH = 'test/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allen_p_sent_120.txt',\n",
       " 'allen_p_sent_125.txt',\n",
       " 'allen_p_sent_134.txt',\n",
       " 'allen_p_sent_137.txt',\n",
       " 'allen_p_sent_142.txt',\n",
       " 'allen_p_sent_156.txt',\n",
       " 'allen_p_sent_159.txt',\n",
       " 'allen_p_sent_15.txt',\n",
       " 'allen_p_sent_161.txt',\n",
       " 'allen_p_sent_164.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = !ls {TRN}\n",
    "#trn_files = !dir /w {TRN}\n",
    "fname[7:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(flist):\n",
    "    return ([a.split(\"_\")[0] + \"_\" + a.split(\"_\")[1] for a in flist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token = get_tokens(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allen_p', 'allen_p', 'allen_p', 'allen_p']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen_p_sent_103.txt</td>\n",
       "      <td>allen_p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen_p_sent_106.txt</td>\n",
       "      <td>allen_p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen_p_sent_110.txt</td>\n",
       "      <td>allen_p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen_p_sent_113.txt</td>\n",
       "      <td>allen_p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen_p_sent_117.txt</td>\n",
       "      <td>allen_p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Filename    Token\n",
       "0  allen_p_sent_103.txt  allen_p\n",
       "1  allen_p_sent_106.txt  allen_p\n",
       "2  allen_p_sent_110.txt  allen_p\n",
       "3  allen_p_sent_113.txt  allen_p\n",
       "4  allen_p_sent_117.txt  allen_p"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = pd.DataFrame({'Filename': fname, 'Token': Token})\n",
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Token</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen_p_sent_103.txt</td>\n",
       "      <td>allen_p</td>\n",
       "      <td>Phillip K , Phillip</td>\n",
       "      <td>Allen</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen_p_sent_106.txt</td>\n",
       "      <td>allen_p</td>\n",
       "      <td>Phillip K , Phillip</td>\n",
       "      <td>Allen</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen_p_sent_110.txt</td>\n",
       "      <td>allen_p</td>\n",
       "      <td>Phillip K , Phillip</td>\n",
       "      <td>Allen</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Filename    Token            FirstName LastName  \\\n",
       "0  allen_p_sent_103.txt  allen_p  Phillip K , Phillip    Allen   \n",
       "1  allen_p_sent_106.txt  allen_p  Phillip K , Phillip    Allen   \n",
       "2  allen_p_sent_110.txt  allen_p  Phillip K , Phillip    Allen   \n",
       "\n",
       "                     Email  \n",
       "0  phillip.allen@enron.com  \n",
       "1  phillip.allen@enron.com  \n",
       "2  phillip.allen@enron.com  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc = pd.merge(df_f, df_tag, on=\"Token\")\n",
    "df_proc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9466, 2)\n",
      "(9429, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_f.shape)\n",
    "print(df_proc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search and Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_replace_text_in_file(fn_in, fn_out, src_str, rpc_str):\n",
    "    # Read in the file\n",
    "    with open(fn_in, 'r', errors=\"ignore\") as file :\n",
    "        filedata = file.read()\n",
    "    # Replace the target string\n",
    "        filedata = filedata.replace(src_str, rpc_str)\n",
    "    # Write the file out again\n",
    "    with open(fn_out, 'w') as file:\n",
    "        file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def search_and_replace_regex_in_file(fn_in, fn_out):\n",
    "    # Read in the file\n",
    "    with open(fn_in, 'r', errors=\"ignore\") as file :\n",
    "        line = file.read()\n",
    "        line = re.sub(\n",
    "                   r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\", \n",
    "                   \" @@othr_em@@ \", \n",
    "                   line \n",
    "               )\n",
    "        line = re.sub(\n",
    "                   r\"\"\"(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?\"\"\", \n",
    "                   \" @@othr_ph@@ \", \n",
    "                   line\n",
    "               )\n",
    "        line = re.sub(\n",
    "                   r\"\"\"(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))\"\"\", \n",
    "                   \" @@othr_ws@@ \", \n",
    "                   line\n",
    "               )\n",
    "        line = re.sub(\n",
    "                   r\"\"\"\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\"\"\", \n",
    "                   \" @@othr_dt@@ \", \n",
    "                   line\n",
    "               )\n",
    "        line = re.sub(\n",
    "                   r\"\"\"\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}\"\"\", \n",
    "                   \" @@othr_dt@@ \", \n",
    "                   line\n",
    "               )\n",
    "        line = re.sub(\n",
    "                   r\"\"\"\\d{1,2}(?:(?:am|pm)|(?::\\d{1,2})(?:am|pm)?)\"\"\", \n",
    "                   \" @@othr_tm@@ \", \n",
    "                   line\n",
    "               )\n",
    "    with open(fn_out, 'w') as file:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = \"/home/wk/myProjects/data/Enron/train/\"\n",
    "dir_out = \"/home/wk/myProjects/data/Enron/tag/train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define rule of replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in df_proc[\"Filename\"]:    \n",
    "    cond = (df_proc.Filename == fn)\n",
    "    Email = df_proc.Email.where(cond, \"\").max()\n",
    "    search_and_replace_text_in_file(dir_in + fn, dir_out + fn, Email, \"@@Email@@\")\n",
    "    \n",
    "    FirstNames = df_proc.FirstName.where(cond, \"\").max().split(\",\")\n",
    "    FirstNames = [a.lstrip(' ').rstrip(' ') for a in FirstNames]\n",
    "    LastName = df_proc.LastName.where(cond, \"\").max()\n",
    "    LastName\n",
    "    for firstName in FirstNames:\n",
    "        fullName = firstName + ' ' + LastName\n",
    "        search_and_replace_text_in_file(dir_out + fn, dir_out + fn, fullName, \"@@FirstName@@ @@LastName@@ \")\n",
    "        search_and_replace_text_in_file(dir_out + fn, dir_out + fn, firstName, \"@@FirstName@@\") \n",
    "        search_and_replace_regex_in_file(dir_out + fn, dir_out + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfname = !ls {VAL}\\n\\nToken = get_tokens(fname)\\n\\ndf_f = pd.DataFrame({\\'Filename\\': fname, \\'Token\\': Token})\\ndf_f.head()\\n\\ndf_proc = pd.merge(df_f, df_tag, on=\"Token\")\\n\\ndir_in = \"/home/wk/myProjects/data/Enron/test/\"\\ndir_out = \"/home/wk/myProjects/data/Enron/tag/test/\"\\n\\nfor fn in df_proc[\"Filename\"]:    \\n    cond = (df_proc.Filename == fn)\\n    Email = df_proc.Email.where(cond, \"\").max()\\n    search_and_replace_text_in_file(dir_in + fn, dir_out + fn, Email, \"@@Email@@\")\\n    \\n    FirstNames = df_proc.FirstName.where(cond, \"\").max().split(\",\")\\n    FirstNames = [a.lstrip(\\' \\').rstrip(\\' \\') for a in FirstNames]\\n    LastName = df_proc.LastName.where(cond, \"\").max()\\n    LastName\\n    for firstName in FirstNames:\\n        fullName = firstName + \\' \\' + LastName\\n        search_and_replace_text_in_file(dir_out + fn, dir_out + fn, fullName, \"@@FirstName@@ @@LastName@@ \")\\n        search_and_replace_text_in_file(dir_out + fn, dir_out + fn, firstName, \"@@FirstName@@\") \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fname = !ls {VAL}\n",
    "\n",
    "Token = get_tokens(fname)\n",
    "\n",
    "df_f = pd.DataFrame({'Filename': fname, 'Token': Token})\n",
    "df_f.head()\n",
    "\n",
    "df_proc = pd.merge(df_f, df_tag, on=\"Token\")\n",
    "\n",
    "dir_in = \"/home/wk/myProjects/data/Enron/test/\"\n",
    "dir_out = \"/home/wk/myProjects/data/Enron/tag/test/\"\n",
    "\n",
    "for fn in df_proc[\"Filename\"]:    \n",
    "    cond = (df_proc.Filename == fn)\n",
    "    Email = df_proc.Email.where(cond, \"\").max()\n",
    "    search_and_replace_text_in_file(dir_in + fn, dir_out + fn, Email, \"@@Email@@\")\n",
    "    \n",
    "    FirstNames = df_proc.FirstName.where(cond, \"\").max().split(\",\")\n",
    "    FirstNames = [a.lstrip(' ').rstrip(' ') for a in FirstNames]\n",
    "    LastName = df_proc.LastName.where(cond, \"\").max()\n",
    "    LastName\n",
    "    for firstName in FirstNames:\n",
    "        fullName = firstName + ' ' + LastName\n",
    "        search_and_replace_text_in_file(dir_out + fn, dir_out + fn, fullName, \"@@FirstName@@ @@LastName@@ \")\n",
    "        search_and_replace_text_in_file(dir_out + fn, dir_out + fn, firstName, \"@@FirstName@@\") \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
