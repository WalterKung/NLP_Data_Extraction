{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy\n",
    "\n",
    "\n",
    "PATH='/home/wk/myProjects/data/Enron/oper/'\n",
    "\n",
    "TRN_PATH = 'train/'\n",
    "VAL_PATH = 'test/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "bs=32; bptt=500\n",
    "em_sz = 300  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))\n",
    "\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3\n",
    "\n",
    "learner.load_encoder('a_adam3_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos=0; @@othr_ph@@ <- fyi \n",
      "pos=39; @@othr_ph@@ <- 5-4435 \n",
      "pos=58; @@othr_ph@@ <- 51293 \n",
      "pos=61; @@othr_ph@@ <- 96085521 \n",
      "pos=75; @@othr_ph@@ <- 713/345-4435 \n",
      "pos=77; @@othr_ph@@ <- 713/646-2495 \n",
      "...\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "### Test\n",
    "ss=r\"\"\"\n",
    "\n",
    "FYI -\n",
    " \n",
    "A new (shell) Master Financial Agreement has been established in Global Contracts for EOL purposes\n",
    "until the executed originals are received from legal.  I have updated this contract number in EOL's Profile Manager.  \n",
    "Please call me at 5-4435 if you have any questions.  \n",
    " \n",
    "Counterparty:\n",
    "Public Utility District No. 1 of Benton County, Washington\n",
    "CP ID Number:\n",
    "51293\n",
    "Contract Number:\n",
    "96085521\n",
    "Profile Manager Updated On:\n",
    "10/26/01\n",
    " \n",
    " \n",
    "Thanks,\n",
    "Georgi\n",
    " \n",
    " \n",
    "Georgi Landau\n",
    "Enron Net Works\n",
    "(Ph) 713/345-4435\n",
    "(Fx)  713/646-2495\n",
    " \n",
    "\"\"\"\n",
    "s = [TEXT.preprocess(ss)] \n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])\n",
    "\n",
    "ss = copy.deepcopy(s)\n",
    "t=TEXT.numericalize(s)\n",
    "\n",
    "m=learner.model\n",
    "\n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "\n",
    "res,*_ = m(t)\n",
    "for i in range(len(s[0])):\n",
    "    n=res[-1].topk(2)[1]    \n",
    "    predict = TEXT.vocab.itos[n.data[0]]                      \n",
    "    if (predict[0:2] == '@@'):\n",
    "        print(\"pos=\" + str(i) + \"; \" + predict + \" <- \" + s[0][i] , end=' \\n')                    \n",
    "        ss[0][i]=predict\n",
    "        n.data[0] = TEXT.vocab.stoi[predict]\n",
    "    else:\n",
    "        n.data[0] = TEXT.vocab.stoi[s[0][i]]\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos=22; @@othr_ph@@ <- (212) \n",
      "pos=25; @@othr_em@@ <- garyross@pira.com. \n",
      "pos=37; @@othr_ph@@ <- (212) \n",
      "pos=40; @@othr_em@@ <- support@pira.com. \n",
      "pos=82; @@othr_em@@ <- sales@pira.com. \n",
      "...\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "### Test\n",
    "ss=r\"\"\"\n",
    "Attached is PIRA's latest \"API Weekly Comment.\"\n",
    "\n",
    "If you have any questions regarding the report's content, please contact\n",
    "Dr. Gary Ross at (212) 686-6808, email: garyross@pira.com.\n",
    "\n",
    "Contact Client Services regarding PIRA report distribution and address\n",
    "changes at (212) 686-6808, email: support@pira.com.\n",
    "\n",
    "NOTE: Circulation of the \"API Weekly Comment\" outside a Client's\n",
    "licensed distribution area is strictly prohibited. Clients that are\n",
    "unsure of their licensed distribution or require an extension of their\n",
    "current license should contact their PIRA sales representative, or email\n",
    "to sales@pira.com.\n",
    "\n",
    "PIRA Energy Group\n",
    "\"\"\"\n",
    "s = [TEXT.preprocess(ss)] \n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])\n",
    "\n",
    "ss = copy.deepcopy(s)\n",
    "t=TEXT.numericalize(s)\n",
    "\n",
    "m=learner.model\n",
    "\n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "\n",
    "res,*_ = m(t)\n",
    "for i in range(len(s[0])):\n",
    "    n=res[-1].topk(2)[1]    \n",
    "    predict = TEXT.vocab.itos[n.data[0]]                      \n",
    "    if (predict[0:2] == '@@'):\n",
    "        print(\"pos=\" + str(i) + \"; \" + predict + \" <- \" + s[0][i] , end=' \\n')                    \n",
    "        ss[0][i]=predict\n",
    "        n.data[0] = TEXT.vocab.stoi[predict]\n",
    "    else:\n",
    "        n.data[0] = TEXT.vocab.stoi[s[0][i]]\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos=0; @@othr_ph@@ <- please \n",
      "pos=95; @@othr_ph@@ <- 713-853-5035 \n",
      "pos=97; @@othr_ph@@ <- 713-854-3923 \n",
      "pos=99; @@othr_ph@@ <- 713-646-8272 \n",
      "...\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "### Test\n",
    "ss=r\"\"\"\n",
    "Please use the next week to clean up our database of delivery locations and regions currently still in Enpower.   I would like to start the database clean with only the key hubs listed:\n",
    "\n",
    "NEPOOL PTF\n",
    "NY Zone J\n",
    "NY Zone G\n",
    "NY Zone A\n",
    "Ontario\n",
    "PJM East Hub\n",
    "PJM West Hub\n",
    "PJM West\n",
    "Cinergy\n",
    "Com-Ed\n",
    "TVA\n",
    "Entergy\n",
    "SOCO\n",
    "ERCOT South (FP)\n",
    "ERCOT North (Basis)\n",
    "\n",
    "Let's use this opportunity to clean up Enpower and start with a truly clean set of books.  \n",
    "Team - Am I missing anthing?\n",
    "\n",
    "Kevin Presto\n",
    "Vice President, East Power Trading\n",
    "Phone:  713-853-5035\n",
    "Cell:  713-854-3923\n",
    "Fax:  713-646-8272\n",
    "\"\"\"\n",
    "s = [TEXT.preprocess(ss)] \n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])\n",
    "\n",
    "ss = copy.deepcopy(s)\n",
    "t=TEXT.numericalize(s)\n",
    "\n",
    "m=learner.model\n",
    "\n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "\n",
    "res,*_ = m(t)\n",
    "for i in range(len(s[0])):\n",
    "    n=res[-1].topk(2)[1]    \n",
    "    predict = TEXT.vocab.itos[n.data[0]]                      \n",
    "    if (predict[0:2] == '@@'):\n",
    "        print(\"pos=\" + str(i) + \"; \" + predict + \" <- \" + s[0][i] , end=' \\n')                    \n",
    "        ss[0][i]=predict\n",
    "        n.data[0] = TEXT.vocab.stoi[predict]\n",
    "    else:\n",
    "        n.data[0] = TEXT.vocab.stoi[s[0][i]]\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')\n",
    "print(len(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
