{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy\n",
    "\n",
    "\n",
    "PATH='/home/wk/myProjects/data/Enron/oper/'\n",
    "\n",
    "TRN_PATH = 'train/'\n",
    "VAL_PATH = 'test/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "bs=24; bptt=100\n",
    "em_sz = 300  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))\n",
    "\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3\n",
    "\n",
    "learner.load_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH=Path('/home/wk/myProjects/data/Enron/tag/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[str(i) for i in PATH.iterdir()]\n",
    "#PATH/'here.txt'.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'message-id: <25459858.1075845925938.javamail.evans@thyme> date: mon, 24 jul 2000 11:03:00 -0700 (pdt) from: kay.mann@enron.com to: sheila.tweed@enron.com subject: re: vepco/fyi mime-version: 1.0 content-type: text/plain; charset=us-ascii content-transfer-encoding: 7bit x-from: kay mann x-to: sheila tweed x-cc: x-bcc: x-folder: \\\\kay_mann_june2001_3\\\\notes folders\\\\sent x-origin: mann-k x-filename: kmann.nsf to tell you the truth, this stuff is difficult for me to retain, so i could be completely off base. i would like to have herman walk through it again. from: sheila tweed@ect on 07/24/2000 05:30 pm to: kay mann/corp/enron@enron cc: subject: re: vepco/fyi it makes one wonder whether one can be in any position in these deals and not be in a lease. maybe we should ask herman to describe one. i was under the assumption that if the ppa is not plant specific, there is less of a concern on who the epc contractor is. i also thought the o&m affiliate was fatal even if we sold down the equity. have i missed the question again?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test\n",
    "ss=r\"\"\"\n",
    "Message-ID: <25459858.1075845925938.JavaMail.evans@thyme>\n",
    "Date: Mon, 24 Jul 2000 11:03:00 -0700 (PDT)\n",
    "From: kay.mann@enron.com\n",
    "To: sheila.tweed@enron.com\n",
    "Subject: Re: VEPCO/FYI\n",
    "Mime-Version: 1.0\n",
    "Content-Type: text/plain; charset=us-ascii\n",
    "Content-Transfer-Encoding: 7bit\n",
    "X-From: Kay Mann\n",
    "X-To: Sheila Tweed\n",
    "X-cc: \n",
    "X-bcc: \n",
    "X-Folder: \\Kay_Mann_June2001_3\\Notes Folders\\Sent\n",
    "X-Origin: MANN-K\n",
    "X-FileName: kmann.nsf\n",
    "\n",
    "To tell you the truth, this stuff is difficult for me to retain, so I could \n",
    "be completely off base. I would like to have Herman walk through it again.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "From: Sheila Tweed@ECT on 07/24/2000 05:30 PM\n",
    "To: Kay Mann/Corp/Enron@ENRON\n",
    "cc:  \n",
    "\n",
    "Subject: Re: VEPCO/FYI  \n",
    "\n",
    "It makes one wonder whether one can be in any position in these deals and not \n",
    "be in a lease.  Maybe we should ask Herman to describe one.  I was under the \n",
    "assumption that if the PPA is not plant specific, there is less of a concern \n",
    "on who the EPC contractor is.  I also thought the O&M affiliate was fatal \n",
    "even if we sold down the equity.  Have I missed the question again?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "s = [TEXT.preprocess(ss)] \n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://askubuntu.com/questions/607118/cuda-not-working-after-returning-laptop-from-sleep#750939\n",
    "len(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo rmmod nvidia_uvm\n",
    "#sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.long().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos=1; @@mes_id@@ <- <25459858.1075845925938.javamail.evans@thyme> \n",
      "pos=4; @@othr_dt@@ <- 24 \n",
      "pos=11; @@sndr_email@@ <- kay.mann@enron.com \n",
      "pos=13; @@recr_email1@@ <- sheila.tweed@enron.com \n",
      "pos=25; @@sndr_fn@@ <- kay \n",
      "pos=26; @@sndr_ln@@ <- mann \n",
      "pos=28; @@rcvr_1fn@@ <- sheila \n",
      "pos=29; @@rcvr_1ln@@ <- tweed \n",
      "pos=34; @@sndr_ln@@ <- folders\\sent \n",
      "pos=36; @@sndr_ln@@ <- mann-k \n",
      "pos=70; @@rcvr_1fn@@ <- sheila \n",
      "pos=71; @@rcvr_1ln@@ <- tweed@ect \n",
      "pos=72; @@othr_dt@@ <- on \n",
      "pos=77; @@sndr_fn@@ <- kay \n",
      "pos=78; @@sndr_ln@@ <- mann/corp/enron@enron \n",
      "...\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "ss = copy.deepcopy(s)\n",
    "t=TEXT.numericalize(s)\n",
    "#t = t.long().cpu()\n",
    "\n",
    "m=learner.model\n",
    "\n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "\n",
    "#m.cpu()\n",
    "#m.cuda()\n",
    "res,*_ = m(t)\n",
    "for i in range(len(s[0])):\n",
    "    n=res[-1].topk(2)[1]    \n",
    "    predict = TEXT.vocab.itos[n.data[0]]                      \n",
    "    if (predict[0:2] == '@@'):\n",
    "        print(\"pos=\" + str(i) + \"; \" + predict + \" <- \" + s[0][i] , end=' \\n')                    \n",
    "        ss[0][i]=predict\n",
    "        n.data[0] = TEXT.vocab.stoi[predict]\n",
    "    else:\n",
    "        n.data[0] = TEXT.vocab.stoi[s[0][i]]\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ben'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[n.data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 558\n",
       "[torch.cuda.LongTensor of size 1x1 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ben', '<eos>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TEXT.vocab.itos[e] for e in n.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 558\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
